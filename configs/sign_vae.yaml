# SignGPT3 VAE Training Config (MldVae - Continuous VAE)
# Based on MotionGPT3's MLD VAE architecture

NAME: SignGPT3_vae_mld
DEBUG: False
ACCELERATOR: 'gpu'
NUM_NODES: 1
DEVICE: [0]
FOLDER: experiments
FOLDER_EXP: experiments/signgpt3

LOGGER:
  TYPE: ['WandbLogger']
  PROJECT: signgpt3
  OFFLINE: True
  SAVE_DIR: experiments/signgpt3/logs
  VAL_EVERY_STEPS: 10

TRAIN:
  STAGE: vae
  BATCH_SIZE: 128
  END_EPOCH: 2000
  RESUME: ''
  PRETRAINED: ''
  PRETRAINED_VAE: ''
  NUM_WORKERS: 8
  instruction_type: 'caption'
  
  OPTIM:
    target: AdamW
    params:
      lr: 2e-4
      betas: [0.9, 0.99]
      weight_decay: 0.0
  
  LR_SCHEDULER:
    target: CosineAnnealingLR
    params:
      T_max: 2000
      eta_min: 1e-6

EVAL:
  SPLIT: val
  BATCH_SIZE: 32
  NUM_WORKERS: 4

TEST:
  SPLIT: test
  BATCH_SIZE: 32
  SAVE_PREDICTIONS: False
  CHECKPOINTS: ''
  REP_I: 0
  NUM_WORKERS: 4

# =============================================================================
# Dataset
# =============================================================================
DATASET:
  target: motGPT.data.H2S.H2SDataModule
  JOINT_TYPE: smplx
  NFEATS: 120
  NJOINTS: 55
  
  H2S:
    DATASET_NAME: how2sign_csl_phoenix
    # DATASET_NAME: phoenix
    ROOT: /home/user/Projects/research/SOKE/data/How2Sign
    CSL_ROOT: /home/user/Projects/research/SOKE/data/CSL-Daily
    PHOENIX_ROOT: /home/user/Projects/research/SOKE/data/Phoenix_2014T
    MEAN_PATH: /home/user/Projects/research/SOKE/data/CSL-Daily/mean.pt
    STD_PATH: /home/user/Projects/research/SOKE/data/CSL-Daily/std.pt
    FPS: 25
    MAX_MOTION_LEN: 300
    MIN_MOTION_LEN: 40
    MAX_TEXT_LEN: 40
    UNIT_LEN: 4

# =============================================================================
# Metrics
# =============================================================================
METRIC:
  TYPE: ['MRMetrics']
  DIST_SYNC_ON_STEP: True
  DIVERSITY_TIMES: 300
  MM_NUM_TIMES: 10
  MM_NUM_REPEATS: 30

# =============================================================================
# Loss
# =============================================================================
LOSS:
  LAMBDA_REC: 1.0
  LAMBDA_FEATURE: 1.0
  LAMBDA_VELOCITY: 0.0
  LAMBDA_KL: 1e-5
  LAMBDA_LATENT: 1e-5
  LAMBDA_COMMIT: 0.02
  LAMBDA_CLS: 1.0
  LAMBDA_DIFF: 1.0
  ABLATION:
    RECONS_LOSS: l1_smooth

# =============================================================================
# Model
# =============================================================================
model:
  target: motGPT.models.motgpt.MotGPT
  params:
    lm: null
    motion_vae: ${vae.mldvae}
    stage: vae
    debug: ${DEBUG}
    task: t2m
    condition: text
    metrics_dict: ${METRIC.TYPE}
    guidance_scale: 1.0
    codebook_size: 512

# =============================================================================
# VAE Config (MldVae - Continuous VAE)
# =============================================================================
vae:
  mldvae:
    target: motGPT.archs.mld_vae.MldVae  # ← 올바른 경로
    params:
      nfeats: ${DATASET.NFEATS}          # 133
      latent_dim: [1, 256]               # ← 리스트 형식!
      ff_size: 1024
      num_layers: 9
      num_heads: 4
      dropout: 0.1
      activation: gelu
      arch: encoder_decoder
      normalize_before: false
      position_embedding: learned
      code_num: 512
      datatype: h2s                       # Sign language
      ablation: ${ABLATION}               # ← ablation 전달

# =============================================================================
# Ablation Settings (MldVae에 필요)
# =============================================================================
ABLATION:
  VAE_TYPE: mld
  VAE_ARCH: encoder_decoder
  PE_TYPE: mld
  DIFF_PE_TYPE: mld
  SKIP_CONNECT: True      # ← Skip connection 활성화
  MLP_DIST: False         # ← Linear layer for distribution
  IS_DIST: False
  PREDICT_EPSILON: True

SEED_VALUE: 1234
FULL_CONFIG: false